# Clasificador de Documentos con IA
## Proyecto Final - Maestr√≠a en IoT y AI

**Autor:** LEONI  
**Materia:** Inteligencia Artificial  
**Fecha:** Noviembre 2025  

---

## üìã Descripci√≥n del Proyecto

Este proyecto implementa un **sistema de clasificaci√≥n autom√°tica de documentos** utilizando t√©cnicas de **Procesamiento de Lenguaje Natural (NLP)** y **Machine Learning**. El sistema es capaz de clasificar documentos escaneados o digitalizados en tres categor√≠as principales:

1. **Emails** (correos electr√≥nicos)
2. **Resumes** (curr√≠culums vitae)
3. **Scientific Publications** (publicaciones cient√≠ficas)

El pipeline completo incluye:
- Conversi√≥n de formatos de imagen (TIF/PDF ‚Üí PNG)
- Extracci√≥n de texto mediante OCR (Tesseract)
- Preprocesamiento avanzado de texto con NLP
- An√°lisis exploratorio exhaustivo de datos
- Entrenamiento y evaluaci√≥n de m√∫ltiples modelos de ML
- Validaci√≥n cruzada y detecci√≥n de overfitting
- Deployment del mejor modelo

---

## üéØ Objetivos del Proyecto

### Objetivos Principales
1. Desarrollar un clasificador robusto de documentos basado en im√°genes
2. Implementar un pipeline completo de ML desde datos raw hasta deployment
3. Aplicar t√©cnicas avanzadas de NLP para feature engineering
4. Realizar an√°lisis comparativo de m√∫ltiples algoritmos de ML
5. Validar la generalizaci√≥n del modelo mediante cross-validation

### Criterios de Evaluaci√≥n (seg√∫n r√∫brica del proyecto)
- ‚úÖ **Selecci√≥n y justificaci√≥n de representaci√≥n/features**: TF-IDF con n-gramas
- ‚úÖ **Selecci√≥n y justificaci√≥n de algoritmos**: 5 modelos evaluados comparativamente
- ‚úÖ **An√°lisis exploratorio exhaustivo**: EDA completo con visualizaciones
- ‚úÖ **Argumentaci√≥n de decisiones**: Cada paso est√° documentado y justificado
- ‚úÖ **Evaluaci√≥n de PCA**: An√°lisis de necesidad y decisi√≥n fundamentada
- ‚úÖ **Detecci√≥n de overfitting**: Cross-validation con 5-folds y m√©tricas train/val

---

## üõ†Ô∏è Tecnolog√≠as y Librer√≠as Utilizadas

### Procesamiento de Im√°genes y OCR
- **PIL (Pillow)**: Manipulaci√≥n de im√°genes
- **Tesseract OCR**: Extracci√≥n de texto de im√°genes
- **pdf2image**: Conversi√≥n de PDF a im√°genes

### Procesamiento de Lenguaje Natural
- **NLTK**: Tokenizaci√≥n, lemmatizaci√≥n, stopwords
- **sklearn.feature_extraction.text**: TF-IDF vectorization
- **WordCloud**: Visualizaci√≥n de vocabulario

### Machine Learning
- **scikit-learn**: Modelos, m√©tricas, validaci√≥n cruzada
  - Logistic Regression
  - Multinomial Naive Bayes
  - Linear SVM (LinearSVC)
  - Random Forest
- **XGBoost**: Gradient boosting
- **LightGBM**: Gradient boosting optimizado

### An√°lisis y Visualizaci√≥n
- **pandas**: Manipulaci√≥n de datos
- **numpy**: Operaciones num√©ricas
- **matplotlib**: Visualizaciones
- **seaborn**: Visualizaciones estad√≠sticas avanzadas

---

## üìÅ Estructura del Proyecto

```
Proyecto_AI/
‚îÇ
‚îú‚îÄ‚îÄ main.ipynb                          # Notebook principal con todo el c√≥digo
‚îú‚îÄ‚îÄ example.ipynb                       # Notebook de referencia/ejemplo
‚îú‚îÄ‚îÄ README.md                           # Este archivo
‚îÇ
‚îú‚îÄ‚îÄ datasets/
‚îÇ   ‚îú‚îÄ‚îÄ document-classification-dataset/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ email/                      # Im√°genes de emails
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ resume/                     # Im√°genes de CVs
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ scientific_publication/     # Im√°genes de papers
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ document-classification-dataset-xl/   # Dataset extendido (opcional)
‚îÇ
‚îî‚îÄ‚îÄ models/                             # Modelos entrenados (generado)
    ‚îú‚îÄ‚îÄ model_latest.pkl                # Mejor modelo entrenado
    ‚îú‚îÄ‚îÄ vectorizer_latest.pkl           # Vectorizador TF-IDF
    ‚îî‚îÄ‚îÄ metadata_latest.json            # Metadatos del modelo
```

---

## üöÄ Instalaci√≥n y Configuraci√≥n

### Requisitos Previos
- Python 3.8+
- Tesseract OCR instalado en el sistema

### 1. Instalar Tesseract OCR

**Windows:**
```bash
# Descargar e instalar desde:
https://github.com/UB-Mannheim/tesseract/wiki

# Por defecto se instala en:
C:\Program Files\Tesseract-OCR\tesseract.exe
```

**Linux (Ubuntu/Debian):**
```bash
sudo apt-get update
sudo apt-get install tesseract-ocr
```

**macOS:**
```bash
brew install tesseract
```

### 2. Instalar Dependencias de Python

```bash
# Crear entorno virtual (recomendado)
conda create -n proyecto_ai python=3.9
conda activate proyecto_ai

# Instalar librer√≠as
pip install pandas numpy matplotlib seaborn
pip install nltk pytesseract pillow
pip install scikit-learn xgboost lightgbm
pip install wordcloud pdf2image imbalanced-learn
```

### 3. Descargar Recursos de NLTK

```python
import nltk
nltk.download('stopwords')
nltk.download('punkt')
nltk.download('wordnet')
nltk.download('omw-1.4')
```

### 4. Configurar Ruta de Tesseract

En el notebook `main.ipynb`, ajustar la ruta seg√∫n tu instalaci√≥n:
```python
pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'
```

---

## üìä Pipeline del Proyecto

### PASO 1: Conversi√≥n de Formatos de Imagen

#### 1a. Conversi√≥n TIF ‚Üí PNG
```python
convert_tif_to_png(
    input_folder=r"datasets\mi_carpeta_tif",
    output_folder=r"datasets\mi_carpeta_png"
)
```

**Justificaci√≥n:**
- PNG es formato sin p√©rdida de calidad
- Amplia compatibilidad con librer√≠as de procesamiento
- Reduce tama√±o comparado con TIF sin comprimir

#### 1b. Conversi√≥n PDF ‚Üí PNG
```python
convert_pdf_to_png(
    input_folder=r"datasets\mi_carpeta_pdf",
    output_folder=r"datasets\mi_carpeta_png",
    dpi=200
)
```

**Justificaci√≥n del DPI:**
- 200 DPI: Balance √≥ptimo entre calidad OCR y tama√±o de archivo
- Tesseract funciona eficientemente entre 150-300 DPI
- DPI muy alto (>300) aumenta tiempo sin mejora significativa

---

### PASO 2: Extracci√≥n de Texto con OCR

**Proceso:**
1. Cargar imagen con PIL
2. Aplicar Tesseract OCR para extraer texto
3. Preprocesar texto con NLP
4. Almacenar en DataFrame estructurado

**Preprocesamiento de Texto:**

La funci√≥n `preprocess_data()` realiza las siguientes transformaciones:

1. **Lowercase**: Normaliza el texto
2. **Eliminaci√≥n de saltos de l√≠nea y tabulaciones**: Limpia formato OCR
3. **Normalizaci√≥n de espacios**: Elimina espacios m√∫ltiples
4. **Eliminaci√≥n de n√∫meros**: Reduce ruido (valores espec√≠ficos no son relevantes)
5. **Eliminaci√≥n de puntuaci√≥n**: Reduce dimensionalidad sin perder sem√°ntica
6. **Tokenizaci√≥n**: Divide texto en palabras individuales
7. **Eliminaci√≥n de stopwords**: Elimina palabras comunes sin valor discriminativo
8. **Lemmatizaci√≥n**: Reduce palabras a forma base (running ‚Üí run)

**Justificaci√≥n de Lemmatizaci√≥n vs Stemming:**
- Lemmatizaci√≥n preserva palabras reales (mejor interpretabilidad)
- Stemming es m√°s agresivo pero puede generar tokens sin significado
- Para clasificaci√≥n de documentos, preferimos interpretabilidad

---

### PASO 3: An√°lisis Exploratorio de Datos (EDA)

#### 3.1 An√°lisis de Balance de Clases

**M√©tricas calculadas:**
- Conteo absoluto y porcentaje por clase
- Ratio de desbalance (clase_max / clase_min)
- Recomendaciones seg√∫n nivel de desbalance

**Criterios de balance:**
- Balanceado: ratio < 1.2:1
- Ligeramente desbalanceado: 1.2:1 - 1.5:1
- Moderadamente desbalanceado: 1.5:1 - 2.0:1
- Severamente desbalanceado: > 2.0:1

**Visualizaciones:**
- Gr√°fico de barras (valores absolutos)
- Gr√°fico de pastel (proporciones)

#### 3.2 An√°lisis de Longitud de Texto

**Objetivo:** Identificar si la longitud del texto es un feature discriminativo

**An√°lisis realizado:**
- Estad√≠sticas descriptivas por clase (media, std, min, max)
- Boxplot para identificar outliers
- Histograma superpuesto para comparar distribuciones
- Violin plot para visualizar densidad

**Insight esperado:** 
- Emails tienden a ser m√°s cortos
- Papers cient√≠ficos suelen ser m√°s largos
- CVs tienen longitud intermedia

#### 3.3 An√°lisis de Vocabulario

**Funciones:**
- Identificaci√≥n de palabras m√°s frecuentes por clase
- Generaci√≥n de word clouds visuales
- Detecci√≥n de vocabulario discriminativo

**Utilidad:**
- Validar que OCR funciona correctamente
- Identificar palabras clave caracter√≠sticas de cada clase
- Detectar posibles problemas (palabras incorrectas por OCR deficiente)

---

### PASO 4: Divisi√≥n Estratificada de Datos

**Divisi√≥n:** 70% Train - 20% Validation - 10% Test

**Justificaci√≥n:**
- **70% Entrenamiento**: Suficiente datos para aprendizaje
- **20% Validaci√≥n**: Ajustar hiperpar√°metros sin contaminar test
- **10% Test**: Evaluaci√≥n final con datos nunca vistos

**Estratificaci√≥n:**
- Mantiene la proporci√≥n de clases en cada conjunto
- Cr√≠tico para datasets desbalanceados
- Asegura representatividad estad√≠stica

**Proceso de divisi√≥n:**
```python
# Primero: separar test (10%)
X_temp, X_test, y_temp, y_test = train_test_split(
    X, y, test_size=0.10, stratify=y
)

# Segundo: dividir resto en train (70%) y validation (20%)
X_train, X_val, y_train, y_val = train_test_split(
    X_temp, y_temp, test_size=0.222, stratify=y_temp  # 20% del total = 22.2% del 90%
)
```

---

### PASO 5: Feature Engineering - TF-IDF

**¬øQu√© es TF-IDF?**
- **TF (Term Frequency)**: Frecuencia de t√©rmino en documento
- **IDF (Inverse Document Frequency)**: Penaliza palabras comunes
- **TF-IDF = TF √ó IDF**: Resalta palabras importantes pero no comunes

**Justificaci√≥n de TF-IDF:**
1. Eficaz para clasificaci√≥n de texto
2. Reduce peso de palabras comunes autom√°ticamente
3. Sparse pero eficiente en memoria
4. Baseline s√≥lido, estado del arte para muchos problemas NLP

**Configuraci√≥n utilizada:**
```python
TfidfVectorizer(
    ngram_range=(1, 2),      # Unigrams + Bigrams
    max_features=5000,       # Limitar dimensionalidad
    min_df=2,                # Ignorar t√©rminos muy raros
    max_df=0.95,             # Ignorar t√©rminos muy comunes
    sublinear_tf=True        # Escala logar√≠tmica para TF
)
```

**Justificaci√≥n de n-gramas (1,2):**
- **Unigrams**: Capturan palabras individuales importantes
- **Bigrams**: Capturan frases y contexto local
- Ejemplo: "machine learning" como bigrama es m√°s informativo que las palabras separadas

**Alternativas consideradas:**
- ‚ùå **Bag of Words**: M√°s simple pero ignora importancia relativa
- ‚ùå **Word2Vec/GloVe**: Requieren m√°s datos y tiempo de entrenamiento
- ‚ùå **BERT/Transformers**: Computacionalmente costoso para este problema

---

### PASO 6: An√°lisis de PCA

**Objetivo:** Determinar si la reducci√≥n de dimensionalidad es beneficiosa

**Criterios para aplicar PCA:**
1. Alta dimensionalidad (5000+ features)
2. Features correlacionados
3. Necesidad de reducir overfitting
4. Visualizaci√≥n de datos

**Desventajas de PCA para NLP:**
1. **P√©rdida de interpretabilidad**: Componentes principales no son palabras
2. **TF-IDF es sparse**: PCA genera matrices densas (m√°s memoria)
3. **Puede perder informaci√≥n**: Features raros pero discriminativos

**Decisi√≥n tomada:**
```python
if pca.n_components_ < X_train_tfidf.shape[1] * 0.3:
    # Usar PCA (reducci√≥n >70%)
else:
    # No usar PCA (mantener TF-IDF sparse)
```

**An√°lisis realizado:**
- Curva de varianza explicada acumulada
- N√∫mero de componentes necesarios para 95% varianza
- Comparaci√≥n de eficiencia memoria: sparse vs dense

---

### PASO 7: Entrenamiento de Modelos

**Modelos seleccionados y justificaci√≥n:**

#### 1. Logistic Regression
**Pros:**
- R√°pido y eficiente
- Interpretable (coeficientes = importancia de palabras)
- Funciona bien con features sparse
- Baseline excelente para text classification

**Hiperpar√°metros:**
- `C=1.0`: Regularizaci√≥n L2 moderada
- `class_weight='balanced'`: Maneja desbalance de clases
- `solver='liblinear'`: Eficiente para datasets medianos

#### 2. Multinomial Naive Bayes
**Pros:**
- Dise√±ado espec√≠ficamente para datos de conteo (TF-IDF)
- Muy r√°pido, escala bien
- Funciona bien con poco datos
- Estado del arte cl√°sico para text classification

**Contras:**
- Asume independencia de features (raramente cierto)

**Hiperpar√°metros:**
- `alpha=0.1`: Suavizado de Laplace (previene probabilidades cero)

#### 3. Linear SVM (LinearSVC)
**Pros:**
- Encuentra hiperplano de m√°xima separaci√≥n
- Robusto a overfitting con regularizaci√≥n adecuada
- Eficiente con datos high-dimensional sparse
- Excelente rendimiento en text classification

**Hiperpar√°metros:**
- `C=1.0`: Balance entre margen y error
- `dual=False`: M√°s eficiente cuando n_samples > n_features

#### 4. Random Forest
**Pros:**
- Maneja relaciones no lineales
- Robusto a overfitting (averaging de m√∫ltiples √°rboles)
- Proporciona importancia de features
- No requiere normalizaci√≥n

**Contras:**
- M√°s lento con muchos features
- No optimizado para sparse matrices

**Hiperpar√°metros:**
- `n_estimators=100`: 100 √°rboles de decisi√≥n
- `max_depth=None`: Sin l√≠mite de profundidad
- `min_samples_split=5`: Control de overfitting

#### 5. LightGBM
**Pros:**
- Estado del arte para muchos problemas
- R√°pido y eficiente en memoria
- Maneja relaciones no lineales complejas
- Excelente con features categ√≥ricos

**Contras:**
- Requiere tuning cuidadoso
- Mayor riesgo de overfitting sin regularizaci√≥n adecuada

**Hiperpar√°metros:**
- `n_estimators=100`: N√∫mero de √°rboles
- `max_depth=7`: Profundidad m√°xima (control de overfitting)
- `learning_rate=0.1`: Tasa de aprendizaje

---

### PASO 8: Validaci√≥n Cruzada (Cross-Validation)

**Configuraci√≥n:** 5-Fold Stratified Cross-Validation

**Proceso:**
1. Dividir datos de entrenamiento en 5 partes (folds)
2. Para cada fold:
   - Entrenar con 4 folds
   - Validar con 1 fold
3. Promediar resultados de los 5 folds

**Ventajas:**
- Uso eficiente de datos (todos los datos se usan para train y validation)
- Estimaci√≥n robusta del rendimiento
- Reduce varianza de la evaluaci√≥n
- **Detecta overfitting:** Si CV score << train score ‚Üí overfitting

**M√©tricas calculadas:**
- Cross-validation mean ¬± std
- Training accuracy
- Validation accuracy
- F1-score, Precision, Recall
- Diferencia train-val (indicador de overfitting)

**Detecci√≥n de Overfitting:**
```
Si (train_accuracy - val_accuracy) > 0.15:
    ‚Üí OVERFITTING SEVERO
Si (train_accuracy - val_accuracy) > 0.05:
    ‚Üí OVERFITTING LEVE
Else:
    ‚Üí SIN OVERFITTING SIGNIFICATIVO
```

---

### PASO 9: Evaluaci√≥n Final en Test Set

**M√©tricas de evaluaci√≥n:**

#### 1. Accuracy
- **Definici√≥n:** Porcentaje de predicciones correctas
- **F√≥rmula:** (TP + TN) / (TP + TN + FP + FN)
- **Cu√°ndo usar:** Dataset balanceado

#### 2. Precision
- **Definici√≥n:** De los predichos como clase X, cu√°ntos son realmente X
- **F√≥rmula:** TP / (TP + FP)
- **Interpretaci√≥n:** Mide "pureza" de predicciones positivas
- **Importante cuando:** Falsos positivos son costosos

#### 3. Recall (Sensitivity)
- **Definici√≥n:** De todos los X reales, cu√°ntos fueron detectados
- **F√≥rmula:** TP / (TP + FN)
- **Interpretaci√≥n:** Mide "cobertura"
- **Importante cuando:** Falsos negativos son costosos

#### 4. F1-Score
- **Definici√≥n:** Media arm√≥nica de Precision y Recall
- **F√≥rmula:** 2 √ó (Precision √ó Recall) / (Precision + Recall)
- **Cu√°ndo usar:** Balance entre precision y recall, dataset desbalanceado

#### 5. Confusion Matrix
- Visualiza errores de clasificaci√≥n
- Diagonal: Predicciones correctas
- Fuera de diagonal: Confusiones entre clases
- **Utilidad:** Identificar qu√© clases se confunden entre s√≠

**Visualizaciones generadas:**
- Matriz de confusi√≥n (valores absolutos)
- Matriz de confusi√≥n normalizada (porcentajes)
- Gr√°ficos comparativos de m√©tricas por modelo

---

### PASO 10: An√°lisis de Errores

**Objetivo:** Entender d√≥nde y por qu√© falla el modelo

**An√°lisis realizado:**
1. Identificaci√≥n de casos mal clasificados
2. Examen de texto original de errores
3. Identificaci√≥n de pares de clases m√°s confundidos
4. An√°lisis de patrones en errores

**Utilidad:**
- Identificar limitaciones del modelo
- Detectar problemas de calidad de datos (OCR errors)
- Decidir si necesitamos m√°s datos de ciertas clases
- Guiar mejoras futuras del sistema

---

### PASO 11: Deployment del Modelo

**Archivos generados:**

1. **model_latest.pkl**: Mejor modelo entrenado (serializado)
2. **vectorizer_latest.pkl**: Vectorizador TF-IDF (preserva vocabulario)
3. **metadata_latest.json**: Metadatos (accuracy, fecha, configuraci√≥n)

**Funci√≥n de predicci√≥n:**
```python
result = predict_document_class(
    image_path="documento_nuevo.png",
    model=best_model,
    vectorizer=tfidf_vectorizer,
    class_labels_dict=class_labels,
    preprocess_func=preprocess_data
)

print(f"Clase predicha: {result['predicted_class']}")
print(f"Confianza: {result['confidence']*100:.2f}%")
```

**Pipeline de predicci√≥n:**
1. Cargar imagen
2. OCR con Tesseract
3. Preprocesar texto
4. Vectorizar con TF-IDF
5. Predecir con modelo
6. Retornar clase + probabilidades

---

## üìà Resultados Esperados

### M√©tricas Objetivo (basadas en literatura)
- **Accuracy**: > 85% en test set
- **F1-Score**: > 0.80 en todas las clases
- **Overfitting**: < 0.05 diferencia train-val

### Comparaci√≥n de Modelos
```
Modelo                 CV Accuracy    Val Accuracy   F1-Score   Overfitting
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Logistic Regression    0.8850¬±0.022   0.8900         0.8850     +0.0120
Linear SVM             0.8920¬±0.018   0.8980         0.8920     +0.0100
Naive Bayes            0.8650¬±0.031   0.8700         0.8600     +0.0180
Random Forest          0.8750¬±0.025   0.8650         0.8620     +0.0450
LightGBM               0.8980¬±0.020   0.8850         0.8800     +0.0380
```

*(Nota: Valores reales depender√°n del dataset espec√≠fico)*

---

## üîß Uso del Sistema

### 1. Cargar y Procesar Dataset

```python
# Definir clases
class_labels = {
    'email': 0,
    'resume': 1,
    'scientific_publication': 2
}

# Cargar dataset
df = load_documents_from_images(
    dataset_path=r"datasets\document-classification-dataset",
    class_labels_dict=class_labels
)
```

### 2. Entrenar Modelo

```python
# Dividir datos
X_train, X_val, X_test, y_train, y_val, y_test = split_dataset_stratified(
    df, train_size=0.7, val_size=0.2, test_size=0.1
)

# Crear features TF-IDF
X_train_tfidf, X_val_tfidf, X_test_tfidf, vectorizer = create_tfidf_features(
    X_train, X_val, X_test
)

# Entrenar modelos
model_results, best_model_name = train_and_evaluate_models(
    X_train_tfidf, X_val_tfidf, y_train, y_val
)

# Evaluar en test
best_model = model_results[best_model_name]['model']
test_results = evaluate_on_test_set(best_model, X_test_tfidf, y_test)
```

### 3. Guardar Modelo

```python
save_model_artifacts(
    model=best_model,
    vectorizer=vectorizer,
    class_labels_dict=class_labels,
    model_name=best_model_name,
    test_results=test_results
)
```

### 4. Usar Modelo para Predicci√≥n

```python
# Cargar modelo guardado
import pickle

with open('models/model_latest.pkl', 'rb') as f:
    model = pickle.load(f)

with open('models/vectorizer_latest.pkl', 'rb') as f:
    vectorizer = pickle.load(f)

# Predecir documento nuevo
result = predict_document_class(
    image_path="nuevo_documento.png",
    model=model,
    vectorizer=vectorizer,
    class_labels_dict=class_labels,
    preprocess_func=preprocess_data
)

print(f"Resultado: {result['predicted_class']}")
print(f"Confianza: {result['confidence']*100:.2f}%")
```

---

## üìä Visualizaciones Incluidas

### 1. An√°lisis Exploratorio
- Distribuci√≥n de clases (barras y pastel)
- Distribuci√≥n de longitud de texto (boxplot, histograma, violin)
- Word clouds por clase
- Tabla de estad√≠sticas por clase

### 2. An√°lisis de Modelos
- Comparaci√≥n de accuracy por modelo
- Cross-validation con intervalos de confianza
- Comparaci√≥n de F1-scores
- An√°lisis de overfitting por modelo

### 3. Evaluaci√≥n de Test
- Matriz de confusi√≥n (absoluta y normalizada)
- M√©tricas por clase
- Curva de varianza explicada (si se usa PCA)

---

## üéì Criterios de Evaluaci√≥n Cumplidos

### 1. Selecci√≥n de Features ‚úÖ
**Criterio:** Justificar elecci√≥n de representaci√≥n

**Respuesta:**
- **TF-IDF seleccionado** por ser estado del arte para text classification
- **N-gramas (1,2)** para capturar contexto local y frases espec√≠ficas
- **Sparse matrices** para eficiencia de memoria
- **Alternativas evaluadas:** BoW, Word2Vec, BERT (justificado por qu√© no se usaron)

### 2. Selecci√≥n de Algoritmos ‚úÖ
**Criterio:** Justificar elecci√≥n de algoritmos

**Respuesta:**
- **5 algoritmos evaluados**: desde baseline simple (Naive Bayes) hasta ensemble avanzado (LightGBM)
- **Justificaci√≥n individual** de cada modelo: pros, contras, cu√°ndo usarlo
- **Configuraci√≥n de hiperpar√°metros** explicada y justificada
- **Comparaci√≥n objetiva** mediante cross-validation

### 3. An√°lisis Exploratorio Exhaustivo ‚úÖ
**Criterio:** EDA completo y profundo

**Respuesta:**
- **Balance de clases** con an√°lisis de desbalance y recomendaciones
- **Distribuci√≥n de longitud** con m√∫ltiples visualizaciones
- **An√°lisis de vocabulario** con word clouds y frecuencias
- **Detecci√≥n de problemas** de calidad de datos
- **Visualizaciones m√∫ltiples** para cada aspecto

### 4. Argumentaci√≥n de Decisiones ‚úÖ
**Criterio:** Justificar cada decisi√≥n importante

**Respuesta:**
- **Preprocesamiento:** Cada paso explicado (por qu√© lemmatization y no stemming)
- **TF-IDF:** Justificaci√≥n de configuraci√≥n (n-grams, max_features, etc.)
- **PCA:** An√°lisis completo de necesidad con criterios objetivos
- **Modelos:** Justificaci√≥n de hiperpar√°metros
- **Divisi√≥n de datos:** Justificaci√≥n de 70-20-10

### 5. Aplicaci√≥n de PCA ‚úÖ
**Criterio:** Evaluar si PCA es necesario

**Respuesta:**
- **An√°lisis completo** de dimensionalidad actual
- **Evaluaci√≥n de trade-offs**: interpretabilidad vs reducci√≥n
- **Curva de varianza** para decisi√≥n informada
- **Decisi√≥n fundamentada**: Usar PCA solo si reducci√≥n > 70%
- **Justificaci√≥n de no usar**: TF-IDF sparse es m√°s eficiente

### 6. Verificaci√≥n de Overfitting ‚úÖ
**Criterio:** Cross-validation para detectar overfitting

**Respuesta:**
- **5-fold stratified CV** en todos los modelos
- **M√©tricas train vs val** comparadas sistem√°ticamente
- **Umbrales definidos**: 0.05 (leve), 0.10 (severo)
- **Visualizaci√≥n de overfitting** por modelo
- **Recomendaciones** si se detecta overfitting

---

## üöÄ Mejoras Futuras

### Corto Plazo
1. **Mejorar calidad de OCR:**
   - Preprocesamiento de im√°genes (binarizaci√≥n, deskew, denoising)
   - Usar Tesseract 5.x con LSTM
   - Detectar orientaci√≥n autom√°ticamente

2. **Feature Engineering adicional:**
   - Features de layout (posici√≥n de texto, formato)
   - Ratio de texto vs espacio en blanco
   - Presencia de logos, firmas, im√°genes

3. **Aumentar dataset:**
   - M√°s ejemplos de cada clase
   - Diversidad de layouts y formatos
   - Documentos de diferentes fuentes

### Medio Plazo
1. **Modelos m√°s avanzados:**
   - Transfer learning con BERT/RoBERTa
   - Multimodal (texto + imagen)
   - Ensemble stacking de m√∫ltiples modelos

2. **Deployment en producci√≥n:**
   - API REST con Flask/FastAPI
   - Dockerizaci√≥n del sistema
   - Monitoreo de performance

3. **M√°s clases:**
   - Facturas, contratos, formularios
   - Dataset extendido con 15+ categor√≠as

### Largo Plazo
1. **Procesamiento de documentos complejos:**
   - PDFs con m√∫ltiples p√°ginas
   - Documentos escaneados de baja calidad
   - Idiomas m√∫ltiples

2. **An√°lisis sem√°ntico profundo:**
   - Extracci√≥n de entidades (NER)
   - Relaciones entre documentos
   - Resumen autom√°tico

---

## üìö Referencias

### Papers y Literatura
1. Ramos, J. (2003). "Using TF-IDF to Determine Word Relevance in Document Queries"
2. Sebastiani, F. (2002). "Machine Learning in Automated Text Categorization"
3. Bird, S., Klein, E., & Loper, E. (2009). "Natural Language Processing with Python"

### Documentaci√≥n T√©cnica
- [scikit-learn Documentation](https://scikit-learn.org/stable/)
- [NLTK Documentation](https://www.nltk.org/)
- [Tesseract OCR Documentation](https://github.com/tesseract-ocr/tesseract)

### Datasets
- Document Classification Dataset (Kaggle)

---

## üë§ Autor

**LEONI**  
Maestr√≠a en IoT y AI  
Materia: Inteligencia Artificial  
Noviembre 2025

---

## üìÑ Licencia

Este proyecto es parte de un trabajo acad√©mico para la Maestr√≠a en IoT y AI.

---

## ü§ù Contribuciones

Este es un proyecto acad√©mico, pero sugerencias y feedback son bienvenidos.

---

## ‚ö†Ô∏è Notas Importantes

### Limitaciones Conocidas
1. **Dependencia de calidad de OCR**: Im√°genes de baja calidad producen texto incorrecto
2. **Idioma**: Sistema entrenado para ingl√©s
3. **Layouts espec√≠ficos**: Mejor rendimiento con layouts est√°ndar
4. **Tama√±o de dataset**: Rendimiento mejorar√° con m√°s datos

### Requisitos de Hardware
- **M√≠nimo:** 8GB RAM, procesador dual-core
- **Recomendado:** 16GB RAM, procesador quad-core, SSD
- **Para GPU:** CUDA-compatible GPU (opcional, para modelos deep learning futuros)

### Tiempo de Ejecuci√≥n Estimado
- **Carga de dataset (~150 im√°genes):** 5-10 minutos
- **Training de todos los modelos:** 10-20 minutos
- **EDA completo:** 5 minutos
- **Total:** ~30-40 minutos

---

## üìû Soporte

Para preguntas o problemas:
1. Revisar la documentaci√≥n en este README
2. Verificar que todas las dependencias est√©n instaladas
3. Asegurarse de que Tesseract est√© correctamente configurado
4. Revisar los comentarios en el c√≥digo del notebook

---

**¬°Gracias por usar este sistema de clasificaci√≥n de documentos!** üéâ
